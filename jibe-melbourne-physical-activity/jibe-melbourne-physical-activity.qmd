---
title: "Modelling physical activity in Melbourne"
format: gfm
execute:
  # no data is to be included in this document, unless intentionally over-ridden
  output: false 
knitr:
  opts_chunk: 
    collapse: true
---

This Quarto markdown document is intended to contain code to predict physical activity for sport and recreation including walking and cycling, given explanatory variables (age, sex, SES, education, has car, etc) that align with the JIBE synthetic population data. This will be conducted to predict physical activity for residents of Melbourne, Australia, using the Australian Bureau of Statistics Australian National Health Survey data (2017-18).

The analysis draws on Belen Zapata-Diomedi's code for cleaning the NHS dataset (../document.qmd), and Belen Zapata-Diomedi, Qin Zhang and Marina Berdokhova's code for a predictive model of marginal metabolic equivalent hours per week (mMET house/week) for Manchester, UK.

To allow this code to be run on different computers and operating systems easily, rather than hardcode data paths for inputs there is a file chooser for the three key inputs used:

1.  ABS NHS households (NHS17HHB.csv)
2.  ABS NHS persons (NHS17PSB.csv)
3.  Melbourne synthetic population (population_final.rds)

The user will be asked to provide paths for these files in this order. If using RStudio or Visual Studio code, there should be a graphical file picker. If using Posit or commandline on linux, you may have to enter the file path string.

## Dependencies

Analysis was conducted using R 4.4.1 using a Quarto markdown document (Quarto 1.5.55) in Positron IDE (2024.10.0), with renv 1.0.11 for package management.

The following packages have been installed using renv:

```         
renv::install(c('dplyr','data.table','ggplot2','vtable','rmarkdown','pscl'))
```

In principle, the R environment for this notebook should be able to be restored by running

```         
renv::restore()
```

Load libaries

```{r}
#| label: load-libraries
library(dplyr)
library(vtable)
library(ggplot2)
library(data.table)
```

## Data

[National Health Survey](https://www.abs.gov.au/statistics/microdata-tablebuilder/available-microdata-tablebuilder/national-health-survey) (NHS) data for 2017-18 were retrieved from the [Microdata Downloads](https://microdatadownload.abs.gov.au/MicrodataDownload/login.xhtml) section of the Australian Bureau of Statistics website on 3 December 2024. ABS Microdata were accessed under the [ABS/Universities Australia Agreement (2024)](https://www.abs.gov.au/statistics/microdata-tablebuilder/absuniversities-australia-agreement) by Carl Higgs (RMIT University). The NHS Microdata data descriptions are available for download [here](https://www.abs.gov.au/statistics/microdata-tablebuilder/available-microdata-tablebuilder/national-health-survey#data-item-lists).

NHS microdata are provided in CSV, SAS, SPSS, or Stata formats. The CSV data do not have labels, hence the `haven` package could be installed to read the labelled data in .dta (Stata) format. However, perhaps labels are not required --- for now, CSV will be used to keep things simple.

| File (csv, dta, etc) | Description                |
|----------------------|----------------------------|
| NHS17HHB             | Household level data       |
| NHS17SPB             | Person level data          |
| NHS17A3B             | Alcohol day level data     |
| NHS17A4B             | Alcohol type level data    |
| NHS17CNB             | Conditions level data      |
| NHS17MDB             | Medications level data     |
| NHS17HLB             | Health Literacy level data |

: ABS NHS 2017-18 Microdata files

The household data contain geographic attributes and could potentially be used to restrict the sample, e.g. to residents of urban areas within Greater Melbourne. Sensitivity analysis could be conducted to evaluate the impact of this decision, e.g. relative to all persons and all persons living in Australian urban regions.

Household variables of interest include:

| Variable                 | Description                                                                             | Comment           |
|------------------|----------------------|--------------------------------|
| ABSHIDB                  | Household identifier                                                                    | Link with persons |
| STATE16                  | State or Territory (ASGS 2016)                                                          | 2 == Victoria     |
| NUMPERBC                 | Number                                                                                  |                   |
| of persons  in household | 0, 1, 2, 3, 4, 5, 6==6+                                                                 |                   |
| SA1SF2DN                 | SEIFA - Index of Relative Socio-economic Disadvantage - 2016 - SA1 - Deciles - National |                   |

Person-level variables of interest (see data dictionaries for detailed codes) include:

| Variable                   | Description                             | Comment                                                                                                                                                 |
|------------------|----------------------|--------------------------------|
| ABSPID                     | Person identifier                       | person number within household                                                                                                                          |
| ABSHIDB                    | Household identifier                    | Link with households, but actually does not match for CURF records                                                                                      |
| AGEB                       | Age of person                           | 1== 0-4 years  … 19 == 85 years+                                                                                                                        |
| SEX                        | Sex of person                           | 1==Male, 2==Female                                                                                                                                      |
| LFSBC                      | Labour force status                     | 0==NA, 1==Employed, 2==Unemployed, 3==Not in the labour force                                                                                           |
| HYSCHCBC                   | Highest year of school completed        | 0==NA, 1==Postgraduate, ... 13==Never attended school                                                                                                   |
| HIGHLVLBC                  | Level of highest educational attainment | 0==NA, 1==Postgraduate, ... 13==Never attended school                                                                                                   |
| EMPSTAT                    | Labour force full-time/part-time status | 0==NA, 1==Employed full time ... 6 Not in labour force                                                                                                  |
| Walk for recreation (mins) | EXFSRMIN                                | Total minutes walked for fitness, recreation or sport in last week (for at least 10 minutes)                                                            |
| Walk for transport (mins)  | EXTRAMIN                                | Total minutes spent walking for transport in last week (for at least 10 minutes)                                                                        |
| Moderate exercise (mins)   | EXLWMMIN                                | Total minutes undertaken moderate exercise last week (for example, a light jog, strenght and toning exercises, lifting small boxes and sweeping)        |
| Vigorous exercise (mins)   | EXLWVMIN                                | Total minutes undertaken vigorous exercise last week (for example, playing basketball, running, lifting heavy boxes, and strength and toning exercises) |

## Methods

### Read and join NHS data

Adults aged 18 years and over from the persons dataset are left joined to the household data, with only the relevant variables retained. The core exposure variables are renamed to enhance readability of the subsequent code.

```{r}
#| label: load-NHS17HHB.csv-NHS17SPB.csv
# choose household file (may require GUI IDE like RStudio/PositStudio/VSCode)
NHS17HHB.csv <- file.choose()
# choose person file (may require GUI IDE like RStudio/PositStudio/VSCode)
NHS17SPB.csv <- file.choose()
data <- list(
    households = read.csv(NHS17HHB.csv),
    persons = read.csv(NHS17SPB.csv)
)
```

```{r}
#| label: merge-nhs-data
#| output: true

nhs <- dplyr::left_join(
            data$households %>% 
                select(
                    c( 
                        "ABSHIDB",
                        "STATE16", 
                        "NUMPERBC",
                        "SA1SF2DN"
                    )
                ),
            data$persons %>% 
                select(
                    c(
                        "ABSHIDB",
                        "ABSPID",
                        "AGEB",
                        "SEX",
                        "LFSBC",
                        "STDYFTPT",
                        "HYSCHCBC",
                        "HIGHLVBC",
                        "EXFSRMIN",
                        "EXTRAMIN",
                        "EXLWMMIN",
                        "EXLWVMIN"
                    )
                ) %>% rename(
                    walk_recreation_min=EXFSRMIN,
                    walk_transport_min=EXTRAMIN,
                    mod_excercise_min=EXLWMMIN,
                    vig_excercise_min=EXLWVMIN
                )%>% 
                filter(
                    AGEB > 4
                ), 
        by = c("ABSHIDB")
        ) 
nhs %>% st(out='kable')
```

### Read and consider the synthetic population data

To predict recreationals mMETs for the synthetic population, we need to understand how the variables are structured and ensure that our NHS derived data that we will use in modelling has a comparable structure. We'll load up the data and consider a summary of variables to better understand this.

I am using [data.table](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) as it is meant to be optimised for handling large datasets, like this synthetic population. This performs subsequent operations deriving new variables much faster.

```{r}
#| label: load-synthetic-population-population_final.rds
#| output: true
population_final.rds <- file.choose()
pp <- readRDS(population_final.rds) %>% as.data.table()
pp %>% st(out='kable')
```

Considering the above, I think the following points are worth considering as model refinements:

-   Represent age in years (e.g. using bracket mid-point) as "Age". This would better model age as a continuous variable, for direct prediction using the synthetic population. A caveat to that would be consideration of whether age is better modelled as linearly (a more parsimonious approach) or non-linearly (which its current treatment as a factor variable allows for, but complicates things and doesn't directly translate to the synthetic population variable that is continuous age in years).
    -   on the other hand, there is an `age_cat` variable, however I think the model would have more power if age could be modelled as continuous. Having said that it will be good to consult with Belen and Qin to get their recommendations and plans for usage.
-   Represent sex as a binary indicator 'female' having 0 (male) and 1 (female)
-   Simplify employment as a binary variable "is_employed" with values of 0 (no) and 1 (yes).
-   Simplify education as a three level variable education, having values 'low', 'medium', 'high'. While it might be that this could be represented as a pseudo continuous variable (0, 1, 2), I think its best to not assume its linear and leave it as a categorical factor variable. Break points for low, medium and high may be subjective; need to consult what this represent in synthetic population. For now, have assumed any tertiary education (Bachelor and higher) is high; Year 10, 11, 12, and Certificates higher than III are medium; and certificates I/II, or Year 9 or lower is low.
-   There is a variable 'IRSAD' that might be disadvantage but it ranges from -1 to 11, so is not clear what this represents (not simply deciles, and not quintiles)
-   other considerations:
    -   The synthetic population seems to have 'student' as a category in RelationshipStatus -- if that does identify someone as a student, then perhaps we can consider 'is_student' in the model for mMETs.
    -   hhSize is present in synthetic population. It may not be conceptually relevant, but is present in household data for NHS, so we could consider its appropriateness for the model.
    -   hhCar is in synethic population, but there is no data to represent this in the NHS data, that I can see.

### Data preparation

Missing data or NA values (e.g 99997 and 99998) are replaced as missing, while maximum values of walking time variables are truncated at 840 minutes to constrain influence of extreme outliers.

SA1 Index of Relative Socio-economic Disadvantage (IRSD; `SA1SF2DN`) is rescaled to use quintiles rather than deciles, for consistency with the synthetic population, with '1' being most deprived and '5' being least deprived.

Two age variables will be created for consideration, first as a factor variable and second in years, using the first age bracket year.

To match the synthetic population data for Melbourne a binary indicator 'is_employed' will be created, along with a possible supplementary indicator 'is_student' that could be derived for the synthetic population.

Education will be summarised using categories of low, medium and high for direct comparison with the synthetic population.

Marginal metabolic equivalent hours per week (mMET hours/week; `mmet`) are calculated as the sum of hours spent walking for recreation, doing moderate exercise and doing vigorous exercise, with each respectively multiplied by the metabolic equivalent of these tasks (METs) minus one (already in MMETs in code).

When deriving factor variables I have set ordered to False, as the alternative setting needlessly over-complicates the modelling (i.e. derives polynomial functions) and limits our capacity to transfer predictions for the synthetic population (see https://stackoverflow.com/questions/57297771/interpretation-of-l-q-c-4-for-logistic-regression).

Remember that SA1 IRSD ranges from 1 (most deprived) to 5 (least deprived).

```{r}
#| label: setup-pa-data
#| output: true
MMET_MOD <- 3.5 # As in meta analysis GArcia et al. 
MMET_VIG <- 7 # As in meta analysis GArcia et al. 
MMET_CYCLING <- 5.8 # From ithimr (check)
MMET_WALKING <- 2.5 # From ithimr (check)

pa_data <- nhs  %>%
    mutate_all(~ ifelse( . %in% c(99997, 99998), NA, .)) %>%
    mutate(
        walk_recreation_min = case_when(
                walk_recreation_min > 840 ~ 840, 
                TRUE ~  walk_recreation_min # handles unexpected values using default
            ),
        walk_transport_min = case_when(
                walk_transport_min > 840 ~ 840, 
                TRUE ~ walk_transport_min
            ),
        mod_excercise_min = case_when(
                mod_excercise_min > 840 ~ 840, 
                TRUE ~ mod_excercise_min
            ),
        vig_excercise_min = case_when(
                vig_excercise_min > 840 ~ 840, 
                TRUE ~ vig_excercise_min
            )
    ) %>%
    mutate(
        irsd_sa1 = case_when(
            SA1SF2DN %in% c(1, 2) ~ 1,
            SA1SF2DN %in% c(3, 4) ~ 2,
            SA1SF2DN %in% c(5, 6) ~ 3,
            SA1SF2DN %in% c(7, 8) ~ 4,
            SA1SF2DN %in% c(9, 10) ~ 5
        )
    ) %>% 
  mutate(
    age_years = case_when(
        AGEB == 5 ~ 18,
        AGEB == 6 ~ 20,
        AGEB == 7 ~ 25,
        AGEB == 8 ~ 30,
        AGEB == 9 ~ 35,
        AGEB == 10 ~ 40,
        AGEB == 11 ~ 45,
        AGEB == 12 ~ 50,
        AGEB == 13 ~ 55,
        AGEB == 14 ~ 60,
        AGEB == 15 ~ 65,
        AGEB == 16 ~ 70,
        AGEB == 17 ~ 75,
        AGEB == 18 ~ 80,
        AGEB == 19 ~ 85,
        TRUE ~ NA_real_  # Handle unexpected values
    ),
        AGEB = factor(
            AGEB, 
            levels = 5:19, 
            labels = c("18-19","20-24", "25-29", "30-34", "35-39", 
                        "40-44", "45-49", "50-54", "55-59", 
                        "60-64", "65-69", "70-74", "75-79", 
                        "80-84", "≥85"),
            ordered = FALSE
        ),
    female=ifelse(SEX==2,1,0),
    is_employed=case_when(
            LFSBC==1 ~ 1,
            LFSBC %in% c(0,2,3) ~ 0
        ),
    is_student=ifelse(STDYFTPT %in% c(1,2),1,0),
    education = case_when(
        HIGHLVBC %in% c(1,2) ~ 2,
        HIGHLVBC %in% c(3,7) ~ 1,
        HIGHLVBC %in% c(8,12) ~ 0,
        TRUE ~ NA_real_  # Handle unexpected values
        ),
    education = factor(
        education,
        levels=0:2,
        labels=c('low','medium','high'),
        ordered=FALSE
    )
    )  %>%
    mutate(
        mmet_hrs_wk_recreation =
            walk_recreation_min/60* MMET_WALKING + 
            mod_excercise_min/60 * MMET_MOD + 
            vig_excercise_min/60 * MMET_VIG, 
        mmet_hrs_wk_total = 
            walk_transport_min/60 * MMET_WALKING + 
            walk_recreation_min/60* MMET_WALKING +
            mod_excercise_min/60 * MMET_MOD + 
            vig_excercise_min/60 * MMET_VIG,
        mmet_hrs_wk_recreation_zero = ifelse(mmet_hrs_wk_recreation == 0, 1, 0)
    ) 

pa_data %>% st(out='kable')
```

### Exploratory data analysis

The following function can be used for retrieving core summary statistics that can be subsequently combined in a comparison table, for example, comparing sub-groups and overall for relevant variables, and against external reference standards.

```{r}
summary_stats <- function(
    data,
    variable
) {
    summary.table <- data %>%
        summarise(
            count = sum(!is.na(get(variable))),
            mean = mean(get(variable), na.rm = TRUE),
            sd = sd(get(variable), na.rm = TRUE),
            min = min(get(variable), na.rm = TRUE),
            p25 = quantile(get(variable), 0.25, na.rm = TRUE),
            p50 = median(get(variable), na.rm = TRUE),
            p75 = quantile(get(variable), 0.75, na.rm = TRUE),
            max = max(get(variable), na.rm = TRUE)
        ) 
    return (summary.table)
}

mmets_summaries <- list()
```

#### Summary statistics of mMET hours/week for prediction model (recreation only)

The variable `mmet_hrs_wk_recreation` combines moderate recreational, vigorous recreational and walking for recreation acitivies.

```{r}
desc <- "NHS (recreation)"
var <- 'mmet_hrs_wk_recreation'
mmets_summaries[['recreation']] = rbind(
    cbind(
        summary=desc, 
        sex="Women",
        summary_stats(pa_data %>% filter(SEX==2),var)
    ),
    cbind(
        summary=desc, 
        sex="Men",
        summary_stats(pa_data %>% filter(SEX==1),var)
    ),
    cbind(
        summary=desc, 
        sex="Overall",
        summary_stats(pa_data,var)
    )
)
```

#### Summary statistics of mmets for comparison with Meta analysis (recreational exercise, and walking for recreation and transport)

The variable `mmet_hrs_wk_total` combines moderate recreational, vigorous recreational and walking for recreation and transport activities.

```{r}
desc <- "NHS (total)"
var <- 'mmet_hrs_wk_total'
mmets_summaries[['total']]  <- rbind(
    cbind(
        summary=desc, 
        sex="Women",
        summary_stats(pa_data %>% filter(SEX==2),var)
    ),
    cbind(
        summary=desc, 
        sex="Men",
        summary_stats(pa_data %>% filter(SEX==1),var)
    ),
    cbind(
        summary=desc, 
        sex="Overall",
        summary_stats(pa_data,var)
    )
)
```

This estimate of total mMET hours/week can support comparisons with meta-analysis results.  According to https://shiny.mrc-epid.cam.ac.uk/meta-analyses-physical-activity/ the marginal MET hours per week overall, and by sex for all-cause mortality was,


| summary                   | sex     | count | mean   | sd | min | p25  | p50   | p75   | max    |
|---------------------------|---------|-------|--------|----|-----|------|-------|-------|--------|
| Meta-analysis | Men     |       | 18.698 |    | 0   | 2.73 | 10.66 | 23.87 | 156.45 |
| Meta-analysis | Women   |       | 17.352 |    | 0   | 2.61 | 10.66 | 22.82 | 103.6  |
| Meta-analysis | Overall |       | 16.908 |    | 0   | 2.35 | 10.5  | 22.5  | 130.02 |



```{r}
#| label: compare-mmets
#| output: true

meta_analysis_results <- data.frame(
  summary = rep("meta-analysis (total)", 3),
  sex = c("Men", "Women", "Overall"),
  count = c(NA, NA, NA),
  mean = c(18.698, 17.352, 16.908),
  sd = c(NA, NA, NA),
  min = c(0, 0, 0),
  p25 = c(2.73, 2.61, 2.35),
  p50 = c(10.66, 10.66, 10.5),
  p75 = c(23.87, 22.82, 22.5),
  max = c(156.45, 103.6, 130.02)
)

mmets_comparison <- rbind(
        rbindlist(mmets_summaries),
        meta_analysis_results
    )
options(knitr.kable.NA = '-')
knitr::kable(
    mmets_comparison,
    caption = "Marginal MET hours per week",
    digits=3
)
```

#### Age

mMET hours per week by age backet -- there may be some non-linearity (e.g. 18-19 year olds median METS are lower, but perhaps not meaningfully so), but broadly, younger people have higher mMETs:

```{r}
#| label: visualise-age-distribution
#| output: true
ggplot(pa_data,aes(x=AGEB, y=mmet_hrs_wk_recreation)) + geom_boxplot() + coord_flip()
qplot(x=pa_data$age_years,y=pa_data$mmet_hrs_wk_recreation, geom='smooth', span =0.5)
```

Looking at the qplot, to me it seems reasonable on grounds of parsimony to model the relationship between age and mMET hours/week as a linear function. There is a drop off after 70, however our data is relatively sparse beyond there and our last category does capture persons older than 85. Its easier to interpret the story from the qplot than boxplots too.

#### Correlations

For now I have included both education variables in the below exploratory data analysis, although most likely a derived combined variable for education will be used, pending discussion with the team. The State variable is also included to get a sense of how variables differ across Australian states; Victorian-specific results could be expected to be mostly drawn from Melbourne, and this could be explored in a sensitivity analysis.

Many of our variables are factor variables for which direct numeric correlations could be misleading (i.e. they aren't necessarily ordinal or linear, e.g. labour force status, or 'NA' values in educational attainment).

```{r}
#| label: explore-correlations
#| output: true
cor=as.data.frame(lapply(pa_data[, c("irsd_sa1", "age_years", "female", "is_employed", "is_student", "education", "NUMPERBC", "mmet_hrs_wk_recreation")], as.numeric))
cor=na.omit(cor)
correlation_matrix <- cor(cor) %>% as.data.frame()
# corrplot(correlation_matrix %>% as.double(), method = "number",order = "FPC",type="lower") 
correlation_matrix[order(correlation_matrix$mmet_hrs_wk_recreation),] %>% round(2)
```

None of the variables in themselves are strongly associated with mMET hours/week. As indicated above, age in years has a negative association. Being female is similarly associated with lower mMET hours/week. Number of persons in household and being a student were not associated with mMETs and need not be included in the model. Employment, lower socio-economic deprivation, and higher degree of education had weak positive associations with mMET hours/week.

#### Clustering

Persons are theoretically clustered within households. If there is more than one person within each household, as this data structure implies, this clustering should be accounted for in the model. The following checks the maximum number of persons within households, and confirms that only one person is associated with each household and so clustering within households will not be required in the model.

```{r}
#| label: explore-clustering
#| output: true
pa_data %>%
  group_by(ABSHIDB) %>%
  summarise(num_persons = n()) %>%
  summarise(max_persons = max(num_persons))
```

#### Set up data for modelling

Select relevant variables and only retain records with full data.

```{r}
#| label: collate-modelling-data
#| output: true
pa_data =pa_data%>%
  select(ABSPID, age_years, female, is_employed, education, irsd_sa1, mmet_hrs_wk_recreation, mmet_hrs_wk_recreation_zero)%>%
  na.omit()

pa_data %>% st(out='kable')
```

Copy a subset of data for persons who record at least some mMET hours/week

```{r}
#| label: collate-modelling-positive-mMETS-data
#| output: true
pa_data_over0=pa_data[pa_data$mmet_hrs_wk_recreation>0,]
pa_data_over0 %>% st(out='kable')
```

### Modelling

The modelling approach (and earlier data preparation) draws on code from the Manchester physical activity modelling R code file `otherSportPA_hurdle_v3.R` authored by Qin Zhang, Belen Zapata-Diomedi and Marina Berdokhova.

#### Modelling mMETS hours/week

```{r}
#| label: model-total-mMETs
#| output: true
m.mMETs_recreational <- list()

m.mMETs_recreational$linear <- lm(
    mmet_hrs_wk_recreation ~ female+age_years+is_employed+education+irsd_sa1,
    data = pa_data_over0)
summary(m.mMETs_recreational$linear)
```

In this model, most predicted results were slightly under-estimated compared with the observed values (median -5.6 mMET hours/week; IQR -11.7 to 6.3).

#### Modelling zero mMETS hours/week

```{r}
#| label: model-total-mMETS-zero
#| output: true
m.mMETs_recreational$zeroModel <- glm(
    mmet_hrs_wk_recreation_zero ~ female+age_years+is_employed+education+irsd_sa1,
    family = "binomial",
    data = pa_data
)

summary(m.mMETs_recreational$zeroModel)
```

Considering the non-normal nature of mMET hours/week, which is a positively skewed rate variable (a non-negative count of hours per week), it is worth considering whether a Poisson model might be more appropriate and provide a better fit.

```{r}
#| label: consider_model_for_rate_data
#| output: true
hist(pa_data$mmet_hrs_wk_recreation) 
hist(log(pa_data$mmet_hrs_wk_recreation))
summary(pa_data$mmet_hrs_wk_recreation)
mean_mmet <- mean(pa_data$mmet_hrs_wk_recreation)
var_mmet <- var(pa_data$mmet_hrs_wk_recreation)

print(paste("Mean:", mean_mmet))
print(paste("Variance:", var_mmet))
if (var_mmet > 2 * mean_mmet) {
    print("var_mmet > 2 * mean_mmet (Consider using a Negative Binomial or Zero-Inflated Negative Binomial model due to overdispersion)")
}
```

The model may appear appoximately normally distributed on a log scale, it also has considerably over-dispersion so a negative binomial model may be appropriate, potentially accounting for the large number of zeros.

```{r}
#| label: consider_alternate_models
#| output: true
library(MASS)
library(pscl)

m.mMETs_recreational$neg_binom <- glm.nb(
    mmet_hrs_wk_recreation ~ female + age_years + is_employed + education + irsd_sa1,
    data = pa_data
)

summary(m.mMETs_recreational$neg_binom)

# Zero-Inflated Negative Binomial model
pa_data$mmet_hrs_wk_recreation_round <- round(pa_data$mmet_hrs_wk_recreation)

m.mMETs_recreational$zinb <- zeroinfl(
    mmet_hrs_wk_recreation_round ~ female + age_years + is_employed + education + irsd_sa1 | female + age_years + is_employed + education + irsd_sa1,
    data = pa_data,
    dist = "negbin"
)

# Summary of the Zero-Inflated Negative Binomial model
summary(m.mMETs_recreational$zinb)
```

```{r}
#| label: review_models
#| output: true
# Compare AIC values
aic_values <- data.frame(
    Model = c("Linear", "Binomial", "neg_binom", "zinb"),
    AIC = c(
        AIC(m.mMETs_recreational$linear), 
        AIC(m.mMETs_recreational$zeroModel), 
        AIC(m.mMETs_recreational$neg_binom),
        AIC(m.mMETs_recreational$zinb)
    )
)
print(aic_values)
```

The zero-inflated negative binomial model has a better fit of mMET hours/week to the observed values than the linear model (median Pearson residual of -0.4, IQR -0.7, 0.3, range -0.9 to 9), with a lower AIC reflecting the better fit.

### Predictions

```{r}
#| label: montecarlo-prediction-function
MonteCarlo <- function(model, data,facetVar = NA) {
  probability.matrix <- as.vector(predict(model,data,type = "response"))
  MC.prediction <- rep(NA,nrow(data))
  for(n in c(1:nrow(data))) {
    MC.prediction[n] <- runif(1)<=probability.matrix[n]
  }
  data=data%>%mutate(zeroPrediction=MC.prediction)
  return(data)
}
```

```{r}
#| label: predict-total-mMETs-nhs
#| output: true
predicted_mmet <- predict(m.mMETs_recreational$zinb, type = "response")
predicted_binary <- ifelse(predicted_mmet > 0, 1, 0)
actual_binary <- ifelse(pa_data$mmet_hrs_wk_recreation > 0, 1, 0)
confusion_matrix <- table(Predicted = predicted_binary, Actual = actual_binary)
print(confusion_matrix)

results <- data.frame(
    predicted_mmet = predicted_mmet,
    actual_binary = pa_data$actual_binary <- ifelse(pa_data$mmet_hrs_wk_recreation > 0, "Greater than 0", "0")
)
# Generate box plots
ggplot(results, aes(x = actual_binary, y = predicted_mmet)) +
    geom_boxplot() +
    labs(
        title = "Predicted mMET Hours/Week by Actual mMET Hours/Week > 0 Status",
        x = "Actual mMET Hours/Week > 0 Status",
        y = "Predicted mMET Hours/Week"
    ) +
    theme_minimal()
```

While the model overestimates mMET hours for those who were estimated to have accrued none, those with none predicted were significantly lower which may be a more realistic estimate. (i.e. in the real world, it may be unlikely that zero physical activity is conducted, some physical activity does occur incidentally as a result of being alive, so the over-estimation of the 'zero' observed mMET hours/week may not be such a problem, necessarily).

But ... the original zero model still did by far the best at predicting zeros, perhaps using the zero model with negative binomial regression for the over zeros would be the best model.

```{r}
#| label: negative_binomial_model_over0
#| output: true
m.mMETs_recreational$neg_binom_over0 <- glm.nb(
    mmet_hrs_wk_recreation ~ female + age_years + is_employed + education + irsd_sa1,
    data = pa_data_over0
)

summary(m.mMETs_recreational$neg_binom_over0)

# Compare AIC values
aic_values <- data.frame(
    Model = c("Linear", "Binomial", "neg_binom", "zinb","neg_binom_over0"),
    AIC = c(
        AIC(m.mMETs_recreational$linear), 
        AIC(m.mMETs_recreational$zeroModel), 
        AIC(m.mMETs_recreational$neg_binom),
        AIC(m.mMETs_recreational$zinb),
        AIC(m.mMETs_recreational$neg_binom_over0)
    )
)
print(aic_values)
```

The combination of negative binomial model with the zero model appears to outperform the linear model.

```{r}
#| label: zero_model_confusion_matrix
#| output: true

# Make predictions using the zero model
predicted_probabilities <- predict(m.mMETs_recreational$zeroModel, type = "response")

# Convert predicted probabilities to binary outcomes using a threshold of 0.5
predicted_binary <- ifelse(predicted_probabilities > 0.5, 1, 0)

# Actual binary outcomes
actual_binary <- pa_data$mmet_hrs_wk_recreation_zero

# Generate the confusion matrix
confusion_matrix <- table(Predicted = predicted_binary, Actual = actual_binary)
print(confusion_matrix)
```

Review the combined predictions

```{r}
#| label: review_combined_predictions
#| output: true
nonzero_predictions <- predict(
    m.mMETs_recreational$neg_binom_over0, 
    type = "response", 
    newdata = pa_data)
combined_predictions <- ifelse(predicted_probabilities > 0.5, 0, nonzero_predictions)

# Evaluate the model
actual_values <- pa_data$mmet_hrs_wk_recreation
results <- data.frame(
    actual_values = actual_values,
    combined_predictions = combined_predictions
)
ggplot(results, aes(x = actual_values, y = combined_predictions)) +
    geom_point(alpha = 0.5) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    labs(
        title = "Scatter Plot of Actual vs. Predicted mMET Hours/Week",
        x = "Actual mMET Hours/Week",
        y = "Predicted mMET Hours/Week"
    ) +
    theme_minimal()
```

Save the model outputs for usage later

```{r}
#| label: save-model-outputs
#| output: true
# Get today's date
today_date <- format(Sys.Date(), "%d%m%Y")

# Save the RDS file with today's date in the filename
saveRDS(m.mMETs_recreational, paste0("model_total_mMETs_", today_date, ".rds"))
```

#### Predicting mMET hours/week for synthetic population

Now we need to get our synthetic population data into the equivalent format to our model, e.g. by converting string categorical variables to binary indicators and adapting the SEIFA IRSD to quintiles. Then we can use our predictions and apply them to the synthetic population.

```{r}
#| label: prepare-synthetic-population-prediction
#| output: true
# Perform the transformations
pp[, `:=`(
    irsd_sa1 = fifelse(IRSAD %in% c(1, 2), 1,
                fifelse(IRSAD %in% c(3, 4), 2,
                fifelse(IRSAD %in% c(5, 6), 3,
                fifelse(IRSAD %in% c(7, 8), 4,
                fifelse(IRSAD %in% c(9, 10), 5, NA_real_))))),
    age_years = Age,
    female = fifelse(Gender == "Female", 1, 0),
    is_employed = fifelse(is_employed == "Yes", 1, 0),
    education = fifelse(education == 'high', 2,
                fifelse(education == 'medium', 1,
                fifelse(education == 'low', 0, NA_real_)))
)]

# Convert education to a factor
pp[, education := factor(education, levels = 0:2, labels = c('low', 'medium', 'high'), ordered = FALSE)]

# Select the relevant columns
data <- pp[, .(AgentId, age_years, female, is_employed, education, irsd_sa1)]
  

data %>% st(out='kable')
```

#### Prediction of mMET hours/week for synethic population

```{r}
#| label: predict-synpop-mMETs
#| output: true
prediction=MonteCarlo(m.mMETs_recreational$zeroModel,data)
table(prediction$zeroPrediction)
```

#### Join estimates back onto synthetic population

```{r}
#| label: synpop-prediction-outputs
#| output: true
nonzeroPP <- prediction %>% filter(!zeroPrediction)

# the non-zero mMET hours/week negative binomial regression output is on a log scale 
# and must be exponentiated for the correct units
nonzeroPP_predict <- nonzeroPP %>% mutate(
    predicted_log_mmet_hrs_wk_recreation = predict(m.mMETs_recreational$neg_binom_over0, nonzeroPP),
    mMETs_recreational = exp(predicted_log_mmet_hrs_wk_recreation)
)

pp <- pp %>% 
      left_join(
        nonzeroPP_predict %>% dplyr::select('AgentId','mMETs_recreational')
      )
pp <- pp %>% mutate(
    mMETs_recreational = ifelse(is.na(mMETs_recreational), 0, mMETs_recreational)
)
summary(pp$mMETs_recreational)
ggplot(pp)+stat_ecdf(aes(x=mMETs_recreational))
```

```{r}
#| label: save-predicted-mMETS-synpop
#| output: true
fwrite(pp,"pp_health_2021_withTotalMMets.csv")
```

```{r}
#| label: boxplot-mMETs_recreational
#| output: true
# Layout to split the screen
layout(mat = matrix(c(1,2),2,1, byrow=TRUE),  height = c(1,8))
 
# Draw the boxplot and the histogram 
par(mar=c(0, 3.1, 1.1, 2.1))
boxplot(pp$mMETs_recreational, horizontal=TRUE , ylim=c(0,30), xaxt="n" , col=rgb(0.8,0.8,0,0.5) , frame=F)
par(mar=c(4, 3.1, 1.1, 2.1))
hist(pp$mMETs_recreational, breaks=40 , col=rgb(0.2,0.8,0.5,0.5) , border=F , main="" , xlab="Predicted mMET hours/week", xlim=c(0,30))
```

#### Combined comparison

```{r}
#| label: overall-mMETs-comparison
#| output: true
desc <- "Synthetic population (recreation)"
var <- 'mMETs_recreational'
mmets_comparison <- rbind(
    mmets_comparison,
    cbind(
        summary=desc, 
        sex="Women",
        summary_stats(pp %>% filter(Gender=='Female'),var)
    ),
    cbind(
        summary=desc, 
        sex="Men",
        summary_stats(pp %>% filter(Gender=='Male'),var)
    ),
    cbind(
        summary=desc, 
        sex="Overall",
        summary_stats(pp,var)
    )
)

options(knitr.kable.NA = '-')
knitr::kable(
    mmets_comparison,
    caption = "Marginal MET hours per week",
    digits=2
)

```